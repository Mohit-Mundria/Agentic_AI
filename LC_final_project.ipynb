{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "40a497c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import google gemini llm, PromptTemplate, and structured output parser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os, uuid\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Here we import necessary lib for structure output\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import json\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "import requests\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# from newsapi import NewsApiClient\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "9c3b2320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9b81b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\",temperature=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8c465094",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERPER_API_KEY=os.getenv(\"SERPER_API_KEY\")\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")\n",
    "MAILJET_API_KEY=os.getenv(\"MAILJET_API_KEY\")\n",
    "MAILJET_API_SECRET=os.getenv(\"MAILJET_API_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "9e2e9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_STORE: dict[str, dict[str, any]] = {}\n",
    "def save_artifact(prefix: str, obj: any) -> str:\n",
    "    aid = f\"{prefix}_{uuid.uuid4().hex[:8]}\"\n",
    "    ARTIFACT_STORE[aid] = obj\n",
    "    return aid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2acf3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_IDS = {\"news\": None, \"sum\": None, \"sent\": None}\n",
    "RUN_STATE = {\"email_sent\": False}\n",
    "\n",
    "def reset_state():\n",
    "    LAST_IDS.update({\"news\": None, \"sum\": None, \"sent\": None})\n",
    "    RUN_STATE[\"email_sent\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "b55e7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def fetch(company:str)->tuple[str, dict[str, str]]:\n",
    "    \"\"\"This function is used to fetch latest news articles from the Internet about a specific company. The input of this function is the topic on which you want to fetch the news articles. The output SHOULD BE the PYTHON dictionary of latest news articles\"\"\"\n",
    "    \n",
    "    # It is predefined url from newsapi.org that give latest news articles with everything endpoints. For more information visit https://newsapi.org/docs/endpoints/everything\n",
    "    present_date=datetime.now().date()\n",
    "    previous_date=present_date-timedelta(days=2)\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": company,\n",
    "        \"from\": previous_date,\n",
    "        \"to\": present_date,\n",
    "        \"sortBy\": \"popularity\",\n",
    "        \"language\": \"en\",\n",
    "        \"apiKey\": NEWS_API_KEY\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    n=1\n",
    "    articles={}\n",
    "    response_history={}\n",
    "    for i in response.json()[\"articles\"][:5]:\n",
    "        articles[f\"Article {n}\"]= str(i[\"title\"])+\" \"+\" \"+str(i[\"description\"])+\" \"+i[\"url\"]\n",
    "        n=n+1\n",
    "        \n",
    "    artifact_id = save_artifact(\"news\",articles)\n",
    "    LAST_IDS[\"news\"]=artifact_id\n",
    "    \n",
    "    \n",
    "\n",
    "    # content: what the LLM can read (short, informational)\n",
    "    # content = f\"Fetched {len(articles)} articles for '{company}', artifact_id='{artifact_id}\"\n",
    "    content= json.dumps({\"artifact_id\":artifact_id, \"count\": len(articles)})\n",
    "    return content, articles\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d22f2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class summary_font(BaseModel):\n",
    "    headline: str = Field(description=\"Headline of the news article.\")\n",
    "    summarize_text: str =Field(description=\"2-3 sentence summary focused on impact to companies/crypto/markets.\")\n",
    "summary_parser=PydanticOutputParser(pydantic_object=summary_font)\n",
    "    \n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def summarize_text(artifact_id:str)->tuple[str,dict[str,dict[str,str]]]:\n",
    "    \"\"\"This function SHOULD BE summarise the news articles FOR EACH INDIVIDUAL NEWS ARTICLES. The input of this function can be dictionary or string of news articles. The output SHOULD BE A PYTHON DICTIONARY that have  summary of EACH INDIVIDUAL NEWS ARTICLES's descriptions and key points of the news articles. SHOULD NOT RETURN A PYTHON STRING as output.\"\"\"\n",
    "    \n",
    "    if isinstance(artifact_id,dict):\n",
    "        artifact_id=ARTIFACT_STORE[\"artifact_id\"]\n",
    "    # artifact_id=artifact_id[\"artifact_id\"]   \n",
    "    if artifact_id not in ARTIFACT_STORE:\n",
    "        return f\"Error: unknown artifact_id '{artifact_id}'.\", []\n",
    "    \n",
    "    articles_text=ARTIFACT_STORE[artifact_id]\n",
    "\n",
    "            \n",
    "            \n",
    "    prompt=ChatPromptTemplate.from_messages(['system',\"You are a helpful assistant that summarizes news articles. And also give key points of the news articles.\",\n",
    "                                            'human',\"\"\"You are a concise financial news summarizer. Given an article, and MUST follow this format: {format_instructions},\n",
    "                                             Article:\n",
    "                                            {article_text}\"\"\"])\n",
    "    prompt=prompt.partial(format_instructions=summary_parser.get_format_instructions())\n",
    "    summary: dict[str,dict[str,str]]={}\n",
    "    \n",
    "    model_summary=model.with_structured_output(summary_font)\n",
    "    \n",
    "    for i,text in articles_text.items():\n",
    "        formatted_prompt=prompt.format_prompt(article_text=text)\n",
    "        result=model_summary.invoke(formatted_prompt)\n",
    "        # summary[i]=[response.content]\n",
    "        # result=summary_parser.parse(response.content)\n",
    "        summary[i]={\n",
    "            \"headline\":result.headline,\n",
    "            \"summarize_text\":result.summarize_text\n",
    "        }\n",
    "    sum_id=save_artifact(\"sum\",summary) \n",
    "    LAST_IDS[\"sum\"]=sum_id   \n",
    "    # return summary\n",
    "    # content: what the LLM can read (short, informational)\n",
    "    #content = f\"Summarized {len(summary)} articles, artifact_id='{sum_id}'.\"\n",
    "    # # artifact: the real Python dict the next tool will consume\n",
    "    content=json.dumps({\"sum_id\":sum_id,\"count\":len(summary)})\n",
    "    \n",
    "    return content, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6d69550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things that i learned from here, we can not create class inside a @tool, we can't use the partial_variable format with the chatPromptTemplate.\n",
    "\n",
    "class sentiment_schema(BaseModel):\n",
    "        sentiment:Literal[\"Positive\",\"Negative\",\"Neutral\"]=Field(description=\"This is the sentiment of the news articles on market\")\n",
    "        score:float=Field(description=\"This is the impact score of the News Article\")\n",
    "sentiment_parser=PydanticOutputParser(pydantic_object=sentiment)\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def sentiment_analysis(artifact_id:str)->tuple[str,any]:\n",
    "    \"\"\"This function is used to perform sentiment analysis on EACH INDIVIDUAL news articles. The input of the functiom can be string or dictionary of news articles's summary and the output SHOULD BE  sentiment of EACH INDIVIDAUL news articles from postive, negative or neutral and IMPACT SCORE OF EACH INDIVIDUAL NEWS ARTICLES.\"\"\"\n",
    "    prompt=ChatPromptTemplate.from_messages([('system',\"You are a helpful financial sentiment analysis assistant who analysis the summary of news articles and provide a sentiment after analysie all the info and also consider your previous knowledge base to give a accurate sentiment.\"),\n",
    "                                            ('human',\"\"\"    Find sentiment and impact score of EACH INDIVIDUAL NEWS ARTICLES. \n",
    "                                             where:- 100 = News will definitly affect the comapny's market and Stock and financial outlook.- 0 = News will not affect anything. \n",
    "                                             summary: {summary}, output format: {format_instruction}\"\"\")])\n",
    "\n",
    "    \n",
    "    if artifact_id not in ARTIFACT_STORE:\n",
    "        return f\"Error: unknown artifact_id '{artifact_id}'.\", {}\n",
    "    summaries= ARTIFACT_STORE[artifact_id]\n",
    "\n",
    "\n",
    "    prompt=prompt.partial(format_instruction=sentiment_parser.get_format_instructions())\n",
    "    sentiment={}\n",
    "    \n",
    "    model_sentiment=model.with_structured_output(sentiment_schema)\n",
    "    for i, text in summaries.items():\n",
    "        formatted_prompt=prompt.format_prompt(summary=text[\"summarize_text\"])\n",
    "        parsed=model_sentiment.invoke(formatted_prompt)\n",
    "        # Parse response into dict instead of keeping raw JSON string\n",
    "        \n",
    "        sentiment[i] = {\n",
    "        \"sentiment\": parsed.sentiment,\n",
    "        \"score\": float(parsed.score)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    sent_id = save_artifact(\"sent\", sentiment)  \n",
    "    LAST_IDS[\"sent\"]=sent_id \n",
    "    # return sentiment        \n",
    "    # # content: what the LLM can read (short, informational)\n",
    "    # content = f\"Computed sentiment for {len(sentiment)} items, artifact_id='{sent_id}'.\"\n",
    "    # # # artifact: the real Python dict the next tool will consume\n",
    "    content=json.dumps({\"sent_id\":sent_id,\"count\":len(sentiment)})\n",
    "    return content, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "a083a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_id(maybe_id: any) -> str:\n",
    "#     \"\"\"Accept raw id, JSON string {'artifact_id': '...'} or dict and return the bare artifact id.\"\"\"\n",
    "#     if isinstance(maybe_id, str):\n",
    "#         s = maybe_id.strip()\n",
    "#         if s.startswith(\"{\") and s.endswith(\"}\"):\n",
    "#             try:\n",
    "#                 return json.loads(s).get(\"artifact_id\", s)\n",
    "#             except Exception:\n",
    "#                 return s\n",
    "#         return s\n",
    "#     if isinstance(maybe_id, dict):\n",
    "#         return str(maybe_id.get(\"artifact_id\", \"\"))\n",
    "#     return str(maybe_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "0685b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SendEmailArgs(BaseModel):\n",
    "    recipient_email: str = Field(description=\"Destination email address for the report\")\n",
    "\n",
    "@tool(args_schema=SendEmailArgs)\n",
    "def send_market_sentiment_email(recipient_email:str) -> str:\n",
    "    \"\"\"\n",
    "    Tool: Generates a market sentiment report (final dict) THAT SHOULD CONTAIN ONLY THOSE NEWS ARTICLES WHOSE IMPACT SCORE IS EQUAL TO OR ABOVE 50.0, \n",
    "    asks the LLM to format it into an email, \n",
    "    and sends the email via Gmail. THE INPUT OF THIS TOOL SHOULD BE A  EMAIL ADDRESS(STRING) AND SHOULD NOT BE A DICTIONARY\n",
    "    \"\"\"\n",
    "    if RUN_STATE.get(\"email_sent\"):\n",
    "        return f\"Email already sent in this run; skipping.\"\n",
    "\n",
    "    sent_id = LAST_IDS.get(\"sent\")\n",
    "    sum_id = LAST_IDS.get(\"sum\")\n",
    "    if not sent_id or not sum_id:\n",
    "        return \"Error: missing sentiment or summaries; run previous steps first.\"\n",
    "\n",
    "    sentiments = ARTIFACT_STORE.get(sent_id, {})\n",
    "    summaries = ARTIFACT_STORE.get(sum_id, {})\n",
    "    \n",
    "    final_dict = {}\n",
    "    for k, text in sentiments.items():\n",
    "        if k in summaries and float(text.get(\"score\", 0.0)) >= 50.0:\n",
    "            final_dict[k] = {\n",
    "                \"summary\": summaries[k].get(\"summarize_text\", \"\"),\n",
    "                \"sentiment\": text.get(\"sentiment\", \"neutral\"),\n",
    "                \"score\": float(text.get(\"score\", 0.0)),\n",
    "            }\n",
    "    if not final_dict:\n",
    "        return \"No articles above threshold; email not prepared.\"\n",
    "\n",
    "    # Step 2: Ask LLM to write the email body\n",
    "    prompt = prompt = f\"\"\"\n",
    "You are an expert financial analyst. Write a professional and well-formatted market sentiment email. \n",
    "The email should be addressed to an investor, and it must summarize the key news articles and their potential \n",
    "impact on the companyâ€™s market performance.\n",
    "\n",
    "** USE YOUR INPUT PARAMETER AND FILL ALL THE REQUIRED FIELDS IN THE EMAIL LIKE THE COMPANY NAME, CURRENT DATE AND TIME. \n",
    "   DO NOT LEAVE OR MAKE PLACE HOLDER SPACES IN THE EMAIL. WRITE A PROFESSIONAL LOOKING EMAIL BY USING YOUR INPUT PARAMETERS AND OUTPUT KNOWLEDGE.**\n",
    "The final report is: {final_dict}\n",
    "Formatting guidelines(YOU MUST FOLLOW THIS):\n",
    "1. Start with a short professional greeting and introduction (e.g., \"Here is todayâ€™s market sentiment report about the company\").\n",
    "2. For each article in the report:\n",
    "   - Present the information in a clear, professional tone.\n",
    "   - Use bullet points or numbered sections for readability.\n",
    "   - Format the details as(CONSIDER ONLY THOSE NEWS ARTICLES WHOSE IMPACT SCORE SHOULD BE ABOVE OR EQUAL TO 50.0):\n",
    "        â€¢ Description / Summary of the News Article  \n",
    "        â€¢ Impact Score (%)  \n",
    "        â€¢ Sentiment (Positive / Neutral / Negative)  \n",
    "3. End with a short professional closing remark (e.g., \"This analysis is intended to help you understand \n",
    "   the potential market impact. Please review before making decisions.\").\n",
    "   \n",
    "\"sender_password\" is \"urff fdmt uufi nvnh\"\n",
    "\n",
    "Note: sender: Mohit Mundria,      department: Market_Sentiment_Project\n",
    "\n",
    "Ensure the email looks polished, investor-friendly, and ready to be sent as a business email.\n",
    "\"\"\"\n",
    "\n",
    "    email_body = model.invoke(prompt).content\n",
    "\n",
    "\n",
    "    # Step 3: Construct email\n",
    "    msg = MIMEMultipart()\n",
    "    msg[\"From\"] = \"mundriamohit101@gmail.com\"\n",
    "    msg[\"To\"] = recipient_email\n",
    "    msg[\"Subject\"] = \"ðŸ“Š Market Sentiment Report\"\n",
    "    msg.attach(MIMEText(email_body, \"plain\"))\n",
    "\n",
    "    # Step 4: Send via Gmail\n",
    "    try:\n",
    "        with smtplib.SMTP(\"smtp.gmail.com\", 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(\"mundriamohit101@gmail.com\", \"urff fdmt uufi nvnh\")\n",
    "            server.sendmail(\"mundriamohit101@gmail.com\", recipient_email, msg.as_string())\n",
    "        RUN_STATE[\"email_sent\"] = True\n",
    "        return {\"status\": \"success\"}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"failed\", \"reason\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2dcfe9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_prompt_template=PromptTemplate(template=\"\"\"\n",
    "You are a professional financial market sentiment analysis assistant that search for news articles and then prepare a financial report to send via email.  \n",
    "Your job is to:\n",
    "1. Search for recent news articles about the company: {company}.  \n",
    "2. Summarize the news articles with headlines and 2â€“3 line summaries with the help of summarize_text tool with artifact_id.  \n",
    "3. Perform sentiment analysis and assign an impact score with the help of sentiment_analysis tool with sent_id.  \n",
    "4. Prepare a final report that SHOULD contain ONLY THOSE NEWS ARTICLES WHOSE IMPACT SCORE IS EQUAL TO OR ABOVE 50.0  \n",
    "5. Send the report to the user via email.\n",
    "\n",
    "Tools: {tools}\n",
    "When you need to use a tool, use this format:\n",
    "\n",
    "Thought: Do I need to use a tool?  \n",
    "Action: the action to take, must be one of [{tool_names}]  \n",
    "Action Input: the input to the action  \n",
    "Observation: the result of the action  \n",
    "\n",
    "REPEAT THIS UNTIL YOU SEND A EMAIL TO RECIPIENT WITH A FINAL REPORT.  \n",
    "\n",
    "\n",
    "Rules:  \n",
    "- Always format the email in a **clear, professional, investor-friendly** way.  \n",
    "- Do not skip any step.  \n",
    "- Only send filtered results from `final_report`.\n",
    "- The sender email is: mundriamohit101@gmail.com\n",
    "- The recipient email is: {recipient_email}\n",
    "- And app password for the sender email is: urff fdmt uufi nvnh\n",
    "\n",
    "Now, based on the users request, autonomously execute the workflow by invoking the tools in the correct sequence.\n",
    "\n",
    "NOTE: ***YOU SHOULD ENSURE THAT YOU SEND ONLY ONE SUCCESSFULLY EMAIL. DO NOT SEND MORE THEN 1 SUCCESSFULL EMAIL TO A SINGLE RECIPIENT.***\n",
    "\n",
    "Begin!\n",
    ", {agent_scratchpad}\n",
    "\"\"\")#input_variables=[\"tools\",\"tool_names\",\"sender_email\",\"recipient_email\",\"password\"])\n",
    "\n",
    "# master_prompt=master_prompt_template.invoke({\"tools\":[fetch,sentiment_analysis,summarize_text,send_market_sentiment_email],\"sender_email\":\"mundriamohit101gmail.com\",\"recipient_email\":\"mundriamohit100@gmail.com\",\"password\":\"urff fdmt uufi nvnh\",\"tool_names\":[\"fetch\",\"sentiment_analysis\",\"summarize_text\",\"send_market_sentiment_email\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f785d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [fetch, summarize_text, sentiment_analysis, send_market_sentiment_email]\n",
    "agent = create_react_agent(model, tools,prompt=master_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e8f44d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=[fetch, summarize_text, sentiment_analysis, send_market_sentiment_email],\n",
    "    verbose=True,  # Set to True to see tool messages and artifacts in console (e.g., intermediate summaries)\n",
    "    handle_parsing_errors=True,\n",
    "    early_stopping_method=\"force\",\n",
    "    max_iterations=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "0242dcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user wants a financial market sentiment report for the company HAL. I need to fetch news articles, summarize them, perform sentiment analysis, filter based on impact score, and then send the report via email.\n",
      "\n",
      "First, I need to fetch the news articles for HAL.\n",
      "Action: fetch\n",
      "Action Input: HAL\u001b[0m\u001b[36;1m\u001b[1;3m{\"artifact_id\": \"news_77b8aaa3\", \"count\": 5}\u001b[0m\u001b[32;1m\u001b[1;3mI have fetched the news articles for HAL. The next step is to summarize these articles. I will use the `summarize_text` tool for this purpose. The `artifact_id` from the `fetch` tool is \"news_77b8aaa3\".\n",
      "Action: summarize_text\n",
      "Action Input: news_77b8aaa3\u001b[0m\u001b[33;1m\u001b[1;3m{\"sum_id\": \"sum_04ba8b9d\", \"count\": 5}\u001b[0m\u001b[32;1m\u001b[1;3mI have summarized the news articles. Now I need to perform sentiment analysis on each of the summarized articles. I will use the `sentiment_analysis` tool for this. The `sum_id` from the `summarize_text` tool is \"sum_04ba8b9d\".\n",
      "Action: sentiment_analysis\n",
      "Action Input: sum_04ba8b9d\u001b[0m\u001b[38;5;200m\u001b[1;3m{\"sent_id\": \"sent_94a0629a\", \"count\": 5}\u001b[0m\u001b[32;1m\u001b[1;3mI have performed sentiment analysis on the news articles. The next step is to prepare the final report containing only articles with an impact score of 50.0 or above and send it via email. I will use the `send_market_sentiment_email` tool for this. The `sent_id` from the `sentiment_analysis` tool is \"sent_94a0629a\".\n",
      "Action: send_market_sentiment_email\n",
      "Action Input: mundriamohit100@gmail.com\u001b[0m\u001b[36;1m\u001b[1;3m{'status': 'success'}\u001b[0m\u001b[32;1m\u001b[1;3mThe market sentiment report for HAL has been successfully sent to mundriamohit100@gmail.com.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 13.103317354s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 13\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 10.673187634s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe previous observation indicates an \"Invalid Format: Missing 'Action:' after 'Thought:'\". This suggests that the LLM might have been interrupted or there was an issue in the tool execution flow. However, the last successful action was sending the email. The prompt states: \"YOU SHOULD ENSURE THAT YOU SEND ONLY ONE SUCCESSFULLY EMAIL. DO NOT SEND MORE THEN 1 SUCCESSFULL EMAIL TO A SINGLE RECIPIENT.\" Since the email has already been sent successfully, I should not attempt to send another email.\n",
      "\n",
      "Therefore, the process is complete.\n",
      " THEN 1 SUCCESSFULL EMAIL TO A SINGLE RECIPIENT.\" Since the email has already been sent successfully, I should not attempt to send another email.\n",
      "\n",
      "Therefore, the process is complete.\n",
      "\u001b[0mInvalid Format: Missing 'Action Input:' after 'Action:'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 4.803215958s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 2.294671668s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 57.897319977s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 49.62954061s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: `The previous observation \"Invalid Format: Missing 'Action Input:' after 'Action:'\" indicates an issue with the tool execution flow. However, the last successful action was sending the email to `mundriamohit100@gmail.com`. The prompt explicitly states: \"YOU SHOULD ENSURE THAT YOU SEND ONLY ONE SUCCESSFULLY EMAIL. DO NOT SEND MORE THEN 1 SUCCESSFULL EMAIL TO A SINGLE RECIPIENT.\"\n",
      "\n",
      "Since the email has already been sent successfully, and the goal is to send only one email, the task is complete. I will not attempt to send another email or perform any further actions.\n",
      " 1 SUCCESSFULL EMAIL TO A SINGLE RECIPIENT.\"\n",
      "\n",
      "Since the email has already been sent successfully, and the goal is to send only one email, the task is complete. I will not attempt to send another email or perform any further actions.\n",
      "`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RUN_STATE[\"email_sent\"] = False\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"Find news about HAL, summarize them, analyze sentiment and email the report to mundriamohit100@gmail.com.\",\n",
    "    \"company\":\"HAL\",\n",
    "    \"recipient_email\":\"mundriamohit100@gmail.com\"\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce1fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
